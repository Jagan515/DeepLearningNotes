# üìò CONVOLUTIONAL NEURAL NETWORK (CNN) ‚Äî COMPLETE NOTES

![Image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/10/90650dnn2.webp)

![Image](https://www.researchgate.net/publication/374143931/figure/fig4/AS%3A11431281190918268%401695521918070/Architecture-of-CNN-with-convolutional-pooling-fully-connected-layer-and-output.png)

![Image](https://miro.medium.com/0%2Ae-SMFTzO8r7skkpc)

![Image](https://towardsdatascience.com/wp-content/uploads/2019/10/1jIv2CLxdXsxvx60Urc11Tw.png)

---

## 1Ô∏è‚É£ What is CNN?

A **Convolutional Neural Network (CNN)** is a special type of neural network designed **specifically for image and spatial data**.

üîë CNN automatically learns:

* edges
* textures
* shapes
* objects

üëâ Unlike ANN, **CNN preserves spatial structure** of images.

---

## 2Ô∏è‚É£ Why CNN over ANN for Images?

### Problem with ANN

* Images are high-dimensional
* Flattening loses spatial information
* Too many parameters

### CNN solves this by:

* Using **local connections**
* **Weight sharing**
* **Feature extraction**

---

## 3Ô∏è‚É£ CNN Architecture (High Level)

Typical flow:

```
Input Image
 ‚Üí Convolution
 ‚Üí Activation
 ‚Üí Pooling
 ‚Üí Convolution
 ‚Üí Pooling
 ‚Üí Flatten
 ‚Üí Fully Connected
 ‚Üí Output
```

---

## 4Ô∏è‚É£ Input Image Representation

Image shape:

```
(H, W, C)
```

Examples:

* Grayscale ‚Üí `(28, 28, 1)`
* RGB ‚Üí `(224, 224, 3)`

---

## 5Ô∏è‚É£ Convolution Layer (MOST IMPORTANT)

### What is Convolution?

* A **filter/kernel** slides over the image
* Performs **element-wise multiplication**
* Produces a **feature map**

### Mathematical view:

[
\text{Feature Map} = \sum (Image \times Kernel) + Bias
]

üîÅ **Multiplication happens here**

---

## 6Ô∏è‚É£ Filters / Kernels

### Filter

* Small matrix (e.g., 3√ó3, 5√ó5)
* Learns features like:

  * edges
  * corners
  * textures

Each filter has:

* its own **weights**
* its own **bias**

More filters ‚Üí more features learned

---

## 7Ô∏è‚É£ Stride

### What is stride?

* Step size of filter movement

| Stride | Effect                 |
| ------ | ---------------------- |
| 1      | Detailed features      |
| 2      | Smaller output, faster |

---

## 8Ô∏è‚É£ Padding

### Why padding?

* Prevent image shrinking
* Preserve border information

| Padding | Meaning                  |
| ------- | ------------------------ |
| Valid   | No padding               |
| Same    | Output size = input size |

---

## 9Ô∏è‚É£ Output Size Formula (IMPORTANT)

[
\frac{(W - F + 2P)}{S} + 1
]

Where:

* `W` = input size
* `F` = filter size
* `P` = padding
* `S` = stride

---

## üîü Activation Functions in CNN

### Why activation?

* Introduce non-linearity

### Common Activations

#### 1Ô∏è‚É£ ReLU (DEFAULT)

[
f(x) = \max(0, x)
]

‚úÖ Used after every convolution
‚ùå Can cause dying neurons

---

#### 2Ô∏è‚É£ Leaky ReLU

[
f(x) = \max(0.01x, x)
]

‚úÖ Fixes dying ReLU

---

#### 3Ô∏è‚É£ Softmax (Output Layer)

* Used for multi-class classification

---

#### 4Ô∏è‚É£ Sigmoid (Output Layer)

* Used for binary classification

---

## 1Ô∏è‚É£1Ô∏è‚É£ Pooling Layer

### Purpose

* Reduce spatial size
* Reduce computation
* Prevent overfitting

---

### Types of Pooling

#### 1Ô∏è‚É£ Max Pooling (MOST COMMON)

* Takes maximum value

#### 2Ô∏è‚É£ Average Pooling

* Takes average

Typical:

```python
MaxPooling2D(pool_size=(2,2))
```

---

## 1Ô∏è‚É£2Ô∏è‚É£ Feature Maps

* Output of convolution layers
* Each feature map = one learned pattern
* Deeper layers ‚Üí complex features

---

## 1Ô∏è‚É£3Ô∏è‚É£ Flatten Layer

* Converts 2D feature maps ‚Üí 1D vector
* Connects CNN to ANN

```python
Flatten()
```

---

## 1Ô∏è‚É£4Ô∏è‚É£ Fully Connected (Dense) Layer

* Works like ANN
* Performs final decision making

---

## 1Ô∏è‚É£5Ô∏è‚É£ CNN Weights & Bias

### Weights

* Stored in filters
* Shared across image
* Fewer parameters than ANN

### Bias

* One bias per filter
* Shifts activation

---

## 1Ô∏è‚É£6Ô∏è‚É£ Loss Functions in CNN

| Task                  | Output Activation | Loss                     |
| --------------------- | ----------------- | ------------------------ |
| Binary classification | Sigmoid           | Binary Crossentropy      |
| Multi-class           | Softmax           | Categorical Crossentropy |
| Regression            | Linear            | MSE                      |

---

## 1Ô∏è‚É£7Ô∏è‚É£ Backpropagation in CNN

CNN learns by:

1. Forward propagation
2. Loss calculation
3. Backpropagation
4. Updating:

   * filter weights
   * bias

Uses **gradient descent**

---

## 1Ô∏è‚É£8Ô∏è‚É£ Overfitting in CNN

### Signs

* High training accuracy
* Low test accuracy

---

### Solutions

* Data augmentation
* Dropout
* Regularization
* More data

---

## 1Ô∏è‚É£9Ô∏è‚É£ Dropout in CNN

* Randomly disables neurons
* Usually applied to **dense layers**

```python
Dropout(0.5)
```

---

## 2Ô∏è‚É£0Ô∏è‚É£ Batch Normalization (Advanced)

### Purpose

* Faster convergence
* Stable training

Placed:

```text
Conv ‚Üí BatchNorm ‚Üí ReLU
```

---

## 2Ô∏è‚É£1Ô∏è‚É£ Data Augmentation

Artificially increase dataset:

* rotation
* flipping
* zoom
* shifting

Helps reduce overfitting.

---

## 2Ô∏è‚É£2Ô∏è‚É£ CNN Classification Decision

### Binary

```text
output > 0.5 ‚Üí class 1
```

### Multi-class

```text
class = argmax(softmax output)
```

---

## 2Ô∏è‚É£3Ô∏è‚É£ Typical CNN Architecture Example

```python
Conv2D(32, (3,3), activation='relu')
MaxPooling2D(2,2)

Conv2D(64, (3,3), activation='relu')
MaxPooling2D(2,2)

Flatten()
Dense(128, activation='relu')
Dense(10, activation='softmax')
```

---

## 2Ô∏è‚É£4Ô∏è‚É£ When to Use CNN?

‚úÖ Use CNN when:

* Image data
* Spatial relationships matter
* Pattern recognition required

‚ùå Avoid CNN when:

* Tabular data
* Very small datasets

---

## üî• ANN vs CNN (Quick Comparison)

| Feature      | ANN     | CNN       |
| ------------ | ------- | --------- |
| Input        | 1D      | 2D/3D     |
| Spatial info | Lost    | Preserved |
| Parameters   | High    | Low       |
| Best for     | Tabular | Images    |

---

## üß† FINAL MEMORY TABLE

| Component   | Purpose            |
| ----------- | ------------------ |
| Convolution | Feature extraction |
| Filter      | Pattern detector   |
| Pooling     | Downsampling       |
| ReLU        | Non-linearity      |
| Flatten     | CNN ‚Üí ANN          |
| Softmax     | Class probability  |
| Loss        | Error measurement  |

---
