{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6SNdHbd0U9-U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiWLzS_ZU-w9",
        "outputId": "45fc9b6a-9176-44bb-d489-8e704eff8665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ0SpDyFVE0T",
        "outputId": "587d8bce-dac6-4529-a5ec-3f094d7dbdec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(404,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)   # (404, 13)\n",
        "print(y_train.shape)   # (404,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sXAIRpH_VKeV"
      },
      "outputs": [],
      "source": [
        "mean = x_train.mean(axis=0)\n",
        "std = x_train.std(axis=0)\n",
        "\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzQehxcwVNxs",
        "outputId": "4e8b90c2-5978-4fa9-d4dc-907186e8dcd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(layers.Dense(1))  # Output layer (no activation for regression)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "51R6Q0PvVRCC"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',           # Mean Squared Error\n",
        "    metrics=['mae']       # Mean Absolute Error\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdomt0V-VcP0",
        "outputId": "23f5a366-6628-45ee-c938-2c6ec8d68de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 599.3750 - mae: 22.4706 - val_loss: 629.3429 - val_mae: 23.3349\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 563.5543 - mae: 21.8026 - val_loss: 593.9415 - val_mae: 22.6220\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 521.4224 - mae: 20.8363 - val_loss: 557.8169 - val_mae: 21.8620\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 491.0143 - mae: 20.2079 - val_loss: 518.8705 - val_mae: 20.9967\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 415.1860 - mae: 18.6444 - val_loss: 476.3240 - val_mae: 19.9991\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 374.0308 - mae: 17.4978 - val_loss: 429.7969 - val_mae: 18.8376\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 336.0023 - mae: 16.6115 - val_loss: 379.0282 - val_mae: 17.4956\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 289.3079 - mae: 15.1381 - val_loss: 329.0166 - val_mae: 16.0563\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 283.8531 - mae: 14.6805 - val_loss: 279.2533 - val_mae: 14.4658\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 233.8308 - mae: 12.9462 - val_loss: 235.3000 - val_mae: 12.8781\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173.4795 - mae: 10.8854 - val_loss: 198.0421 - val_mae: 11.3986\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 152.5396 - mae: 9.9984 - val_loss: 166.0944 - val_mae: 10.0701\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 122.6848 - mae: 8.9198 - val_loss: 139.7282 - val_mae: 8.9478\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 116.1929 - mae: 8.1167 - val_loss: 120.2357 - val_mae: 8.1574\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 82.2648 - mae: 6.9206 - val_loss: 105.0287 - val_mae: 7.5033\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 70.8876 - mae: 6.1298 - val_loss: 92.4645 - val_mae: 6.9349\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 60.9082 - mae: 6.1089 - val_loss: 82.1410 - val_mae: 6.4487\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 53.0408 - mae: 5.3708 - val_loss: 73.9902 - val_mae: 6.1109\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.7108 - mae: 5.1652 - val_loss: 66.7878 - val_mae: 5.8022\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 47.3867 - mae: 5.0007 - val_loss: 60.4809 - val_mae: 5.5062\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.5924 - mae: 4.6681 - val_loss: 55.4652 - val_mae: 5.2556\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 40.8441 - mae: 4.3899 - val_loss: 51.1421 - val_mae: 5.0690\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.9839 - mae: 3.9934 - val_loss: 47.4298 - val_mae: 4.8989\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0319 - mae: 3.9151 - val_loss: 44.6635 - val_mae: 4.7475\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6906 - mae: 3.8938 - val_loss: 41.8882 - val_mae: 4.5921\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6758 - mae: 3.8008 - val_loss: 39.5232 - val_mae: 4.4607\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.9323 - mae: 3.5377 - val_loss: 37.9662 - val_mae: 4.3699\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.0481 - mae: 3.5033 - val_loss: 36.1202 - val_mae: 4.2660\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.2798 - mae: 3.4914 - val_loss: 34.8512 - val_mae: 4.2213\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25.2787 - mae: 3.5199 - val_loss: 33.1534 - val_mae: 4.1420\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.2827 - mae: 3.4175 - val_loss: 32.0863 - val_mae: 4.0935\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.2588 - mae: 3.5072 - val_loss: 31.1427 - val_mae: 4.0066\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25.5821 - mae: 3.4207 - val_loss: 30.2016 - val_mae: 3.9660\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20.8529 - mae: 3.2402 - val_loss: 29.2664 - val_mae: 3.9152\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.0312 - mae: 3.4092 - val_loss: 28.5773 - val_mae: 3.9001\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.1416 - mae: 3.7629 - val_loss: 27.9875 - val_mae: 3.8851\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.3720 - mae: 3.5624 - val_loss: 27.4158 - val_mae: 3.8415\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.2604 - mae: 3.3946 - val_loss: 26.9609 - val_mae: 3.8197\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.2410 - mae: 3.4533 - val_loss: 26.4892 - val_mae: 3.7808\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.7416 - mae: 3.3499 - val_loss: 26.0312 - val_mae: 3.7588\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.6873 - mae: 3.2515 - val_loss: 25.5043 - val_mae: 3.7214\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.6648 - mae: 2.9984 - val_loss: 25.0503 - val_mae: 3.6718\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 17.3923 - mae: 3.0638 - val_loss: 24.7307 - val_mae: 3.6594\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.0193 - mae: 3.1200 - val_loss: 24.3472 - val_mae: 3.6617\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.6695 - mae: 3.2755 - val_loss: 23.8624 - val_mae: 3.6282\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.8321 - mae: 3.0973 - val_loss: 23.5004 - val_mae: 3.5818\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.9291 - mae: 3.3160 - val_loss: 23.0109 - val_mae: 3.5491\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.2943 - mae: 3.2980 - val_loss: 22.5645 - val_mae: 3.5070\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.9425 - mae: 3.1926 - val_loss: 22.3420 - val_mae: 3.5053\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.1222 - mae: 2.8957 - val_loss: 22.0507 - val_mae: 3.4871\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17.8769 - mae: 3.0559 - val_loss: 21.7574 - val_mae: 3.4679\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.0094 - mae: 3.1631 - val_loss: 21.7537 - val_mae: 3.4996\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.7925 - mae: 2.9781 - val_loss: 21.3092 - val_mae: 3.4464\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.8368 - mae: 2.9509 - val_loss: 20.9390 - val_mae: 3.4114\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.0503 - mae: 2.7766 - val_loss: 20.7154 - val_mae: 3.3863\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.7646 - mae: 3.0819 - val_loss: 20.4420 - val_mae: 3.3672\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.9682 - mae: 2.8183 - val_loss: 20.2337 - val_mae: 3.3517\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.5637 - mae: 2.9598 - val_loss: 20.0434 - val_mae: 3.3368\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.8452 - mae: 2.8626 - val_loss: 19.8066 - val_mae: 3.3242\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.7220 - mae: 2.8065 - val_loss: 19.4570 - val_mae: 3.2892\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.9624 - mae: 2.9884 - val_loss: 19.3205 - val_mae: 3.2822\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 17.3679 - mae: 2.9244 - val_loss: 19.1761 - val_mae: 3.2707\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.2107 - mae: 2.6950 - val_loss: 18.9808 - val_mae: 3.2612\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.1273 - mae: 2.8326 - val_loss: 18.4500 - val_mae: 3.2196\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.4653 - mae: 2.8837 - val_loss: 18.2104 - val_mae: 3.2011\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18.2756 - mae: 2.8975 - val_loss: 18.2703 - val_mae: 3.1867\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.4409 - mae: 2.5714 - val_loss: 17.9556 - val_mae: 3.1732\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15.6161 - mae: 2.7181 - val_loss: 17.8168 - val_mae: 3.1629\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 13.1979 - mae: 2.6964 - val_loss: 17.6085 - val_mae: 3.1442\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.7711 - mae: 2.4611 - val_loss: 17.4983 - val_mae: 3.1388\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.3122 - mae: 2.5659 - val_loss: 17.2973 - val_mae: 3.0952\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 15.9012 - mae: 2.7433 - val_loss: 17.2135 - val_mae: 3.1106\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.8880 - mae: 2.7092 - val_loss: 17.1003 - val_mae: 3.1111\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19.5753 - mae: 2.8532 - val_loss: 16.8499 - val_mae: 3.0812\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.2689 - mae: 2.4629 - val_loss: 16.6668 - val_mae: 3.0605\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.4689 - mae: 2.4007 - val_loss: 16.5147 - val_mae: 3.0475\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.4016 - mae: 2.5565 - val_loss: 16.8554 - val_mae: 3.0311\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.3094 - mae: 2.3659 - val_loss: 16.7075 - val_mae: 3.0471\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.4014 - mae: 2.3159 - val_loss: 16.2943 - val_mae: 3.0146\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.8946 - mae: 2.5603 - val_loss: 16.0385 - val_mae: 2.9895\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.0687 - mae: 2.2569 - val_loss: 15.9157 - val_mae: 2.9759\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.7967 - mae: 2.4313 - val_loss: 15.7994 - val_mae: 2.9520\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.1545 - mae: 2.4181 - val_loss: 15.6812 - val_mae: 2.9429\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.6349 - mae: 2.2947 - val_loss: 15.6994 - val_mae: 2.9641\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.5859 - mae: 2.3233 - val_loss: 15.4058 - val_mae: 2.9324\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.9230 - mae: 2.3628 - val_loss: 15.1813 - val_mae: 2.8801\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6907 - mae: 2.1633 - val_loss: 15.1414 - val_mae: 2.8784\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.0758 - mae: 2.3468 - val_loss: 15.0733 - val_mae: 2.8859\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.7168 - mae: 2.3366 - val_loss: 14.9825 - val_mae: 2.8486\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7609 - mae: 2.0760 - val_loss: 14.8465 - val_mae: 2.8505\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.6919 - mae: 2.2397 - val_loss: 14.8311 - val_mae: 2.8344\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.2713 - mae: 2.3091 - val_loss: 14.7740 - val_mae: 2.8138\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.0585 - mae: 2.1825 - val_loss: 14.6082 - val_mae: 2.8150\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.7189 - mae: 2.3414 - val_loss: 14.6116 - val_mae: 2.8051\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.1139 - mae: 2.4022 - val_loss: 14.4461 - val_mae: 2.7974\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.8573 - mae: 2.3057 - val_loss: 14.5320 - val_mae: 2.7993\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.6273 - mae: 2.1822 - val_loss: 14.3309 - val_mae: 2.7794\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4393 - mae: 2.0876 - val_loss: 14.3851 - val_mae: 2.7723\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0732 - mae: 2.1576 - val_loss: 14.2214 - val_mae: 2.8038\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5612 - mae: 2.1120 - val_loss: 14.0970 - val_mae: 2.7492\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12RM7AFXVgRv",
        "outputId": "115c03ea-6785-4940-f371-a984da26652e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Predicted value: [7.5370436]\n",
            "Actual value: 7.2\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)\n",
        "\n",
        "print(\"Predicted value:\", predictions[0])\n",
        "print(\"Actual value:\", y_test[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqIHRA4PVvqi"
      },
      "source": [
        "## Deep ANN with Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GhpATBgZVxI7"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(13,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mx-cwA0yV0TX"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_fXpWTUIV3zM"
      },
      "outputs": [],
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LInCawuJV9sC",
        "outputId": "178634fd-9a32-4575-dae5-3d7dbd198efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 533.1501 - mae: 20.9889 - val_loss: 440.5805 - val_mae: 18.8978\n",
            "Epoch 2/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 314.5567 - mae: 15.0333 - val_loss: 113.1562 - val_mae: 8.2795\n",
            "Epoch 3/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 80.0451 - mae: 7.0520 - val_loss: 52.2565 - val_mae: 5.5592\n",
            "Epoch 4/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.0645 - mae: 4.3133 - val_loss: 26.7419 - val_mae: 3.9382\n",
            "Epoch 5/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.3672 - mae: 3.4865 - val_loss: 19.9582 - val_mae: 3.4608\n",
            "Epoch 6/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.1919 - mae: 2.8488 - val_loss: 18.0059 - val_mae: 3.3382\n",
            "Epoch 7/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17.4822 - mae: 2.9100 - val_loss: 16.3798 - val_mae: 3.1479\n",
            "Epoch 8/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18.0144 - mae: 2.8678 - val_loss: 15.1827 - val_mae: 3.0442\n",
            "Epoch 9/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.0695 - mae: 2.7330 - val_loss: 14.2217 - val_mae: 2.9956\n",
            "Epoch 10/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.0157 - mae: 2.2835 - val_loss: 14.5378 - val_mae: 2.9524\n",
            "Epoch 11/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.3990 - mae: 2.4696 - val_loss: 14.7854 - val_mae: 3.0106\n",
            "Epoch 12/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.8386 - mae: 2.4123 - val_loss: 14.0956 - val_mae: 2.8766\n",
            "Epoch 13/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4359 - mae: 2.1717 - val_loss: 13.9886 - val_mae: 2.8086\n",
            "Epoch 14/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8506 - mae: 2.2728 - val_loss: 14.8275 - val_mae: 2.9095\n",
            "Epoch 15/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.8869 - mae: 2.4787 - val_loss: 13.6497 - val_mae: 2.8249\n",
            "Epoch 16/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.5755 - mae: 2.3983 - val_loss: 13.6412 - val_mae: 2.8026\n",
            "Epoch 17/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3385 - mae: 1.9760 - val_loss: 14.5258 - val_mae: 2.7510\n",
            "Epoch 18/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9838 - mae: 2.1247 - val_loss: 15.3105 - val_mae: 2.8300\n",
            "Epoch 19/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6748 - mae: 2.1448 - val_loss: 14.9046 - val_mae: 2.7978\n",
            "Epoch 20/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.0517 - mae: 2.1531 - val_loss: 13.4734 - val_mae: 2.7603\n",
            "Epoch 21/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4781 - mae: 2.0868 - val_loss: 13.9594 - val_mae: 2.6957\n",
            "Epoch 22/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8706 - mae: 2.1666 - val_loss: 14.5632 - val_mae: 2.7069\n",
            "Epoch 23/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8887 - mae: 2.0393 - val_loss: 14.9973 - val_mae: 2.7986\n",
            "Epoch 24/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8253 - mae: 1.8999 - val_loss: 14.1309 - val_mae: 2.6879\n",
            "Epoch 25/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4986 - mae: 2.1404 - val_loss: 15.3257 - val_mae: 2.7115\n",
            "Epoch 26/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7557 - mae: 1.9009 - val_loss: 15.0145 - val_mae: 2.6754\n",
            "Epoch 27/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9038 - mae: 1.7987 - val_loss: 14.9739 - val_mae: 2.6151\n",
            "Epoch 28/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5954 - mae: 1.8955 - val_loss: 14.6484 - val_mae: 2.6898\n",
            "Epoch 29/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7195 - mae: 1.9696 - val_loss: 16.3697 - val_mae: 2.6744\n",
            "Epoch 30/300\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4039 - mae: 1.9803 - val_loss: 16.0751 - val_mae: 2.6419\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7d941c8230>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=300,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWmBLpBaWAzN",
        "outputId": "a24b2030-2415-4665-a525-596584654b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.1022 - mae: 2.8862\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[24.30750274658203, 3.093101978302002]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uEfaVnsWGXF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
